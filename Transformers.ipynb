{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch torchtext\n",
        "!pip install torch==2.2.2 torchtext==0.17.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKa0Q0nRoURe",
        "outputId": "9831d0ff-8187-44b9-ccad-ad21dc5687e8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch==2.2.2\n",
            "  Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting torchtext==0.17.2\n",
            "  Downloading torchtext-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch==2.2.2)\n",
            "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.2) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.2) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.2) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.2) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.2) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.2) (1.3.0)\n",
            "Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.17.2-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchtext\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 torchtext-0.17.2 triton-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade safetensors transformers"
      ],
      "metadata": {
        "id": "9NN5YDDQ0DAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n0r-z1hwnRUU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d14abc51-a007-4e0f-e8e9-c63a07470f42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
            "    await result\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-3384007902.py\", line 2, in <cell line: 0>\n",
            "    import torch.nn as nn\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.2+cu121\n"
          ]
        }
      ],
      "source": [
        "# importing required libraries\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import math,copy,re\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torchtext\n",
        "import matplotlib.pyplot as plt\n",
        "warnings.simplefilter(\"ignore\")\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            vocab_size: size of vocabulary\n",
        "            embed_dim: dimension of embeddings\n",
        "        \"\"\"\n",
        "        super(Embedding, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: input vector\n",
        "        Returns:\n",
        "            out: embedding vector\n",
        "        \"\"\"\n",
        "        out = self.embed(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "AHXMlVpCoMgi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self, max_seq_len, embed_model_dim):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            seq_len: length of input sequence\n",
        "            embed_model_dim: emdedding dimension\n",
        "        \"\"\"\n",
        "        super(PositionalEmbedding, self).__init__()\n",
        "        self.embed_model_dim = embed_model_dim\n",
        "\n",
        "        position_embed = torch.zeros(max_seq_len, embed_model_dim)\n",
        "        for pos in range(max_seq_len):\n",
        "          for i in range(embed_model_dim):\n",
        "            if(i%2):\n",
        "              position_embed[pos,i] = math.sin(pos/(10000**((2*i)/embed_model_dim)))\n",
        "            else:\n",
        "              position_embed[pos,i] = math.cos(pos/(10000**((2*i)/embed_model_dim)))\n",
        "        position_embed = position_embed.unsqueeze(0)\n",
        "        self.register_buffer('position_embed', position_embed)\n",
        "    def forward(self, x):\n",
        "      x = x*math.sqrt(self.embed_model_dim)\n",
        "      seq_len = x.size(1)\n",
        "      out = x + torch.autograd.Variable(self.position_embed[:, :seq_len], requires_grad=False)\n",
        "      return out"
      ],
      "metadata": {
        "id": "m_Wdk22GsZcL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, embed_dim, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "    self.embed_dim = embed_dim    #512 dim\n",
        "    self.n_heads = num_heads   #8\n",
        "    self.single_head_dim = int(self.embed_dim/self.n_heads)\n",
        "    self.key = nn.Linear(self.single_head_dim, self.single_head_dim, bias=False)\n",
        "    self.query = nn.Linear(self.single_head_dim, self.single_head_dim, bias=False)\n",
        "    self.value = nn.Linear(self.single_head_dim, self.single_head_dim, bias=False)\n",
        "    self.out = nn.Linear(self.n_heads*self.single_head_dim, self.embed_dim)\n",
        "\n",
        "  def forward(self, key, query, value, mask=None):\n",
        "    batch_size = key.size(0)\n",
        "    seq_len = key.size(1)\n",
        "\n",
        "    # query dimension can change in decoder during inference.\n",
        "    # so we cant take general seq_length\n",
        "    seq_length_query = query.size(1)\n",
        "\n",
        "    key = key.view(batch_size, seq_len, self.n_heads, self.single_head_dim)\n",
        "    query = query.view(batch_size, seq_length_query, self.n_heads, self.single_head_dim)\n",
        "    value = value.view(batch_size, seq_len, self.n_heads, self.single_head_dim)\n",
        "    k = self.key(key)\n",
        "    q = self.query(query)\n",
        "    v = self.value(value)\n",
        "\n",
        "    k = k.transpose(1,2)\n",
        "    q = q.transpose(1,2)\n",
        "    v = v.transpose(1,2)\n",
        "\n",
        "    # adjust key for matrix multiplication\n",
        "    k_adjusted = k.transpose(-1,-2)  #(batch_size, n_heads, single_head_dim, seq_ken)  #(32 x 8 x 64 x 10)\n",
        "    product = torch.matmul(q, k_adjusted)  #(batch_size, n_heads, seq_len_q, seq_len_k)  #(32 x 8 x 10 x 10)\n",
        "\n",
        "    # fill those positions of product matrix as (-1e20) where mask positions are 0\n",
        "    if mask is not None:\n",
        "      product = product.masked_fill(mask == 0, float(\"-1e20\"))\n",
        "\n",
        "    product = product / math.sqrt(self.single_head_dim) #(32 x 8 x 10 x 64) x (32 x 8 x 64 x 10) = #(32x8x10x10)\n",
        "\n",
        "    scores = F.softmax(product, dim=-1)\n",
        "\n",
        "    scores = torch.matmul(scores, v)##(32x8x 10x 10) x (32 x 8 x 10 x 64) = (32 x 8 x 10 x 64)\n",
        "\n",
        "    #concatenated output\n",
        "    concat = scores.transpose(1,2).contiguous().view(batch_size, seq_length_query, self.single_head_dim*self.n_heads) # (32x8x10x64) -> (32x10x8x64)  -> (32,10,512)\n",
        "\n",
        "    output = self.out(concat) #(32,10,512) -> (32,10,512)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "EGQXnGkJi3to"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, embed_dim, num_heads, dropout, forward_expansion):\n",
        "    super(TransformerBlock, self).__init__()\n",
        "    self.attention = MultiHeadAttention(embed_dim, num_heads)\n",
        "    self.norm1 = nn.LayerNorm(embed_dim)\n",
        "    self.norm2 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "    self.feed_forward = nn.Sequential(\n",
        "        nn.Linear(embed_dim, forward_expansion*embed_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(forward_expansion*embed_dim, embed_dim)\n",
        "    )\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, key, query, value):\n",
        "    attention = self.attention(key, query, value)\n",
        "    norm1_out = self.dropout(self.norm1(attention + query))\n",
        "    feed_forward_out = self.feed_forward(norm1_out)\n",
        "    norm2_out = self.dropout(self.norm2(feed_forward_out + norm1_out))\n",
        "    return norm2_out\n",
        ""
      ],
      "metadata": {
        "id": "Ls0gLrD9lPQC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "  def __init__(self, embed_dim, num_heads, dropout, forward_expansion, max_seq_len, num_layers, vocab_size):\n",
        "    super(TransformerEncoder, self).__init__()\n",
        "    self.embedding_layer = Embedding(vocab_size, embed_dim)\n",
        "    self.positional_embedding = PositionalEmbedding(max_seq_len, embed_dim)\n",
        "    self.layers = nn.ModuleList([TransformerBlock(embed_dim, num_heads, dropout, forward_expansion) for _ in range(num_layers)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    embed_out = self.embedding_layer(x)\n",
        "    out = self.positional_embedding(embed_out)\n",
        "    for layer in self.layers:\n",
        "      out = layer(out, out, out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "0sjNxqyZV3tT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self, embed_dim, num_heads, dropout, forward_expansion):\n",
        "    super(DecoderBlock, self).__init__()\n",
        "    self.attention = MultiHeadAttention(embed_dim, num_heads)\n",
        "    self.norm = nn.LayerNorm(embed_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.transformer_block = TransformerBlock(embed_dim, num_heads, dropout, forward_expansion)\n",
        "\n",
        "  def forward(self, enc_out, x, trg_mask):\n",
        "        # 1️⃣ Masked self-attention (Q=K=V from decoder input x)\n",
        "        self_attn_out = self.attention(x, x, x, trg_mask)\n",
        "        x = self.dropout(self.norm(self_attn_out + x))\n",
        "\n",
        "        # 2️⃣ Cross-attention (Q from decoder, K=V from encoder) — no trg_mask here!\n",
        "        out = self.transformer_block(enc_out, x, enc_out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "ud4cod2qoqrU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "  def __init__(self, embed_dim, num_heads, dropout, forward_expansion, max_seq_len, num_layers, vocab_size):\n",
        "    super(TransformerDecoder, self).__init__()\n",
        "    self.embedding_layer = Embedding(vocab_size, embed_dim)\n",
        "    self.positional_embedding = PositionalEmbedding(max_seq_len, embed_dim)\n",
        "    self.layers = nn.ModuleList([DecoderBlock(embed_dim, num_heads, dropout, forward_expansion) for _ in range(num_layers)])\n",
        "    self.ff = nn.Linear(embed_dim, vocab_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x, enc_out, trg_mask):\n",
        "    embed_out = self.embedding_layer(x)\n",
        "    out = self.positional_embedding(embed_out)\n",
        "    out = self.dropout(out)\n",
        "\n",
        "    for layer in self.layers:\n",
        "      out = layer(enc_out, out, trg_mask)\n",
        "    out = self.ff(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "3l9fmVwFxakw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, embed_dim, src_vocab_size, trg_vocab_size, num_heads, dropout, forward_expansion, max_seq_len, num_layers):\n",
        "    super(Transformer, self).__init__()\n",
        "    self.encoder = TransformerEncoder(embed_dim, num_heads, dropout, forward_expansion, max_seq_len, num_layers, src_vocab_size)\n",
        "    self.decoder = TransformerDecoder(embed_dim, num_heads, dropout, forward_expansion, max_seq_len, num_layers, trg_vocab_size)\n",
        "\n",
        "  def make_trg_mask(self, trg):\n",
        "    batch_size, trg_seq_len = trg.shape\n",
        "    mask = torch.tril(torch.ones((trg_seq_len, trg_seq_len), device=trg.device)).bool()\n",
        "    return mask.unsqueeze(0).unsqueeze(0).expand(batch_size, 1, trg_seq_len, trg_seq_len)\n",
        "\n",
        "  def decode(self, src, trg):\n",
        "    \"\"\"\n",
        "        for inference\n",
        "        Args:\n",
        "            src: input to encoder\n",
        "            trg: input to decoder\n",
        "        out:\n",
        "            out_labels : returns final prediction of sequence\n",
        "    \"\"\"\n",
        "    trg_mask = self.make_trg_mask(trg)\n",
        "    enc_out = self.encoder(src)\n",
        "    output = []\n",
        "    batch_size,seq_len = src.shape[0],src.shape[1]\n",
        "    out = trg\n",
        "    for i in range(seq_len):\n",
        "      out = self.decoder(out, enc_out, trg_mask)\n",
        "      out = out[:,-1:,:]\n",
        "      out = out.argmax(-1)\n",
        "      print(out)\n",
        "      output.append(out.item())\n",
        "      out = torch.unsqueeze(out,axis=0)\n",
        "\n",
        "    return output\n",
        "\n",
        "  def forward(self, src, trg):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src: input to encoder\n",
        "            trg: input to decoder\n",
        "        out:\n",
        "            out: final vector which returns probabilities of each target word\n",
        "        \"\"\"\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        enc_out = self.encoder(src)\n",
        "\n",
        "        outputs = self.decoder(trg, enc_out, trg_mask)\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "1SlM0MRKx_f_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab_size = 11\n",
        "target_vocab_size = 11\n",
        "num_layers = 6\n",
        "seq_length= 12\n",
        "\n",
        "\n",
        "# let 0 be sos token and 1 be eos token\n",
        "src = torch.tensor([[0, 2, 5, 6, 4, 3, 9, 5, 2, 9, 10, 1],\n",
        "                    [0, 2, 8, 7, 3, 4, 5, 6, 7, 2, 10, 1]])\n",
        "target = torch.tensor([[0, 1, 7, 4, 3, 5, 9, 2, 8, 10, 9, 1],\n",
        "                       [0, 1, 5, 6, 2, 4, 7, 6, 2, 8, 10, 1]])\n",
        "\n",
        "print(src.shape,target.shape)\n",
        "model = Transformer(embed_dim=512, src_vocab_size=src_vocab_size,\n",
        "                    trg_vocab_size=target_vocab_size, max_seq_len=seq_length,\n",
        "                    num_layers=num_layers, forward_expansion=4, num_heads=8, dropout= 0.2)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQg4rFfkBzBD",
        "outputId": "fdb5f31c-0d79-4fb3-826a-32559cfc77f1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 12]) torch.Size([2, 12])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): TransformerEncoder(\n",
              "    (embedding_layer): Embedding(\n",
              "      (embed): Embedding(11, 512)\n",
              "    )\n",
              "    (positional_embedding): PositionalEmbedding()\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x TransformerBlock(\n",
              "        (attention): MultiHeadAttention(\n",
              "          (key): Linear(in_features=64, out_features=64, bias=False)\n",
              "          (query): Linear(in_features=64, out_features=64, bias=False)\n",
              "          (value): Linear(in_features=64, out_features=64, bias=False)\n",
              "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (feed_forward): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): TransformerDecoder(\n",
              "    (embedding_layer): Embedding(\n",
              "      (embed): Embedding(11, 512)\n",
              "    )\n",
              "    (positional_embedding): PositionalEmbedding()\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x DecoderBlock(\n",
              "        (attention): MultiHeadAttention(\n",
              "          (key): Linear(in_features=64, out_features=64, bias=False)\n",
              "          (query): Linear(in_features=64, out_features=64, bias=False)\n",
              "          (value): Linear(in_features=64, out_features=64, bias=False)\n",
              "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (transformer_block): TransformerBlock(\n",
              "          (attention): MultiHeadAttention(\n",
              "            (key): Linear(in_features=64, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=64, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=64, out_features=64, bias=False)\n",
              "            (out): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (feed_forward): Sequential(\n",
              "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (1): ReLU()\n",
              "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ff): Linear(in_features=512, out_features=11, bias=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = model(src, target)\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4IR9mpJJhAR",
        "outputId": "9f849759-691b-4ae7-8445-5bfafb3abde8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 12, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "model = Transformer(embed_dim=512, src_vocab_size=src_vocab_size,\n",
        "                    trg_vocab_size=target_vocab_size, max_seq_len=seq_length,\n",
        "                    num_layers=num_layers, forward_expansion=4, num_heads=8, dropout= 0.2)\n",
        "\n",
        "\n",
        "\n",
        "src = torch.tensor([[0, 2, 5, 6, 4, 3, 9, 5, 2, 9, 10, 1]])\n",
        "trg = torch.tensor([[0]])\n",
        "print(src.shape,trg.shape)\n",
        "out = model.decode(src, trg)\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyZ62qXYS4eX",
        "outputId": "ed3085d7-3d45-44c8-8e2e-f78efeb7037a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 12]) torch.Size([1, 1])\n",
            "tensor([[6]])\n",
            "tensor([[[3]]])\n",
            "tensor([[[[1]]]])\n",
            "tensor([[[[[4]]]]])\n",
            "tensor([[[[[[4]]]]]])\n",
            "tensor([[[[[[[3]]]]]]])\n",
            "tensor([[[[[[[[2]]]]]]]])\n",
            "tensor([[[[[[[[[3]]]]]]]]])\n",
            "tensor([[[[[[[[[[2]]]]]]]]]])\n",
            "tensor([[[[[[[[[[[3]]]]]]]]]]])\n",
            "tensor([[[[[[[[[[[[6]]]]]]]]]]]])\n",
            "tensor([[[[[[[[[[[[[6]]]]]]]]]]]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6, 3, 1, 4, 4, 3, 2, 3, 2, 3, 6, 6]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# ----- Hyperparameters -----\n",
        "src_vocab_size = 11\n",
        "trg_vocab_size = 11\n",
        "embed_dim = 512\n",
        "num_heads = 8\n",
        "num_layers = 6\n",
        "dropout = 0.2\n",
        "forward_expansion = 4\n",
        "max_seq_len = 12\n",
        "learning_rate = 1e-4\n",
        "num_epochs = 200\n",
        "\n",
        "# ----- Model, Loss, Optimizer -----\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Transformer(embed_dim, src_vocab_size, trg_vocab_size, num_heads, dropout, forward_expansion, max_seq_len, num_layers).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)  # ignoring padding index if 0 is pad token\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# ----- Dummy Training Data (replace with real data) -----\n",
        "src = torch.tensor([[0, 2, 5, 6, 4, 3, 9, 5, 2, 9, 10, 1],\n",
        "                    [0, 2, 8, 7, 3, 4, 5, 6, 7, 2, 10, 1]]).to(device)\n",
        "\n",
        "trg = torch.tensor([[0, 1, 7, 4, 3, 5, 9, 2, 8, 10, 9, 1],\n",
        "                    [0, 1, 5, 6, 2, 4, 7, 6, 2, 8, 10, 1]]).to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    # Decoder input = all except last token of target\n",
        "    dec_input = trg[:, :-1]\n",
        "    # Target for loss = all except first token of target\n",
        "    dec_target = trg[:, 1:]\n",
        "\n",
        "    output = model(src, dec_input)  # shape: (batch, seq_len-1, vocab_size)\n",
        "\n",
        "    # Reshape for loss\n",
        "    output = output.reshape(-1, output.shape[-1])   # (batch*(seq_len-1), vocab_size)\n",
        "    dec_target = dec_target.reshape(-1)             # (batch*(seq_len-1))\n",
        "\n",
        "    loss = criterion(output, dec_target)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}]  Loss: {loss.item():.4f}\")\n",
        "\n",
        "print(\"Training complete ✅\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqfNHkM0hrF1",
        "outputId": "92aa12b0-cf55-4b5c-ee16-46384ebfa24a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/200]  Loss: 2.2254\n",
            "Epoch [20/200]  Loss: 2.2335\n",
            "Epoch [30/200]  Loss: 2.0626\n",
            "Epoch [40/200]  Loss: 2.3020\n",
            "Epoch [50/200]  Loss: 2.0602\n",
            "Epoch [60/200]  Loss: 1.9241\n",
            "Epoch [70/200]  Loss: 1.7000\n",
            "Epoch [80/200]  Loss: 1.5404\n",
            "Epoch [90/200]  Loss: 1.3410\n",
            "Epoch [100/200]  Loss: 1.0879\n",
            "Epoch [110/200]  Loss: 0.9519\n",
            "Epoch [120/200]  Loss: 0.6945\n",
            "Epoch [130/200]  Loss: 0.5535\n",
            "Epoch [140/200]  Loss: 0.4356\n",
            "Epoch [150/200]  Loss: 0.3458\n",
            "Epoch [160/200]  Loss: 0.4664\n",
            "Epoch [170/200]  Loss: 0.3732\n",
            "Epoch [180/200]  Loss: 0.2881\n",
            "Epoch [190/200]  Loss: 0.3040\n",
            "Epoch [200/200]  Loss: 0.2971\n",
            "Training complete ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src = torch.tensor([[0, 2, 5, 6, 4, 3, 9, 5, 2, 9, 10, 1]])\n",
        "trg = torch.tensor([[0]])\n",
        "print(src.shape,trg.shape)\n",
        "out = model.decode(src, trg)\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YBTRdPM0JEw",
        "outputId": "e6d7d3f9-e591-45d2-92ed-67cb4f627abd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 12]) torch.Size([1, 1])\n",
            "tensor([[8]])\n",
            "tensor([[[10]]])\n",
            "tensor([[[[4]]]])\n",
            "tensor([[[[[0]]]]])\n",
            "tensor([[[[[[4]]]]]])\n",
            "tensor([[[[[[[10]]]]]]])\n",
            "tensor([[[[[[[[4]]]]]]]])\n",
            "tensor([[[[[[[[[4]]]]]]]]])\n",
            "tensor([[[[[[[[[[4]]]]]]]]]])\n",
            "tensor([[[[[[[[[[[0]]]]]]]]]]])\n",
            "tensor([[[[[[[[[[[[3]]]]]]]]]]]])\n",
            "tensor([[[[[[[[[[[[[9]]]]]]]]]]]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8, 10, 4, 0, 4, 10, 4, 4, 4, 0, 3, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}